#!/usr/bin/python3
import requests # Import python library in order to handle HTTP requests.
import sys # Import python library in order to manage arguments.

# This script attemps to perform a mapping job over a webapplication by catching all the paths present on the webpage and collect it in an array and displayin them.

URL = sys.argv[1] # We retrieve the URL through the first argument.

if ":" in URL.split("://")[1]:

    ip = URL.split("://")[1].split(":")[0]

elif "/" in URL.split("://")[1]:

    ip = URL.split("://")[1].split("/")[0]

urlList = [] # We make a list-array object to store the directory candidates
isFollowed = {} # We make dictionary array to check if the path that has to be checked. 


def checkUrlList(URL):
   if URL in urlList:
       return True
   else:
       return False

def isFollowedCheck(URL):
   for entry in isFollowed.keys():
       if URL != entry:
           return False
       else:
           if isFollowed[URL] == "yes":
               return True
           else:
               return False
                               
urlList.append(URL)

for URL in urlList:
   if isFollowedCheck(URL) != True:  # First we check if the URL we wanna see if it is available has been already visited. If is not, we checked an proceed to follow it.

       # The code attemps to retrieve for the main page all the lines in which there are present the URL and parse it in order to retrieve the path.
       page = requests.get(URL) 
       isFollowed[URL] = "yes"
       
       start = "http" 
       for line in page.text.split("\n"): 
           if "http" in line:
               if ip in line:
                   if "\">" in line:
                       end = "\">"
                   else:
                       end = "\" "
                   sliced = line[line.index(start):line.index(end)]
                   if "\"" in sliced:
                       end = "\""
                       parsedURL = sliced[sliced.index(start):sliced.index(end)]
                   else:
                       parsedURL = sliced
                   if checkUrlList(parsedURL) == False: # Then we check if this path is already in out urlList and if not we append and pass to the next iteration.
                       urlList.append(parsedURL)
                       isFollowed[parsedURL] = "no"

for URL in urlList:
   print(URL)
